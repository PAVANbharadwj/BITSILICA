{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "def60f41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency of each word:\n",
      " {'2025-03-01': 5, '14:05:00,001': 1, 'INFO': 2, 'ModuleA': 3, '-': 5, 'User': 1, 'login': 1, 'successful': 1, 'for': 5, 'user': 2, \"'alice'.\": 1, '14:05:05,002': 1, 'DEBUG': 1, 'ModuleB': 1, 'Retrieved': 1, 'data': 1, \"'alice'\": 1, 'from': 1, 'cache.': 1, '14:05:10,003': 1, 'ERROR': 1, 'ModuleC': 1, 'Payment': 3, 'processing': 2, 'failed': 1, 'transaction': 3, 'ID': 3, '12345.': 3, '14:05:15,004': 1, 'WARNING': 1, 'retry': 2, 'scheduled': 1, '14:05:20,005': 1, 'succeeded': 1, 'on': 1}\n"
     ]
    }
   ],
   "source": [
    "#1.Basic Syntax and Data Types\n",
    "f = open(\"applicaiton_logs.txt\",\"r\")\n",
    "\n",
    "data = f.read()\n",
    "\n",
    "words = data.split()\n",
    "freq = {}\n",
    "\n",
    "for word in words:\n",
    "    freq[word] = freq.get(word,0)+1\n",
    "    \n",
    "f.close()\n",
    "    \n",
    "print(\"The frequency of each word:\\n\",freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "43214ad2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2025-03-01 16:30:00,100 INFO [Init] - Application started.\n",
      "2025-03-01 16:31:00,200 DEBUG [Auth] - Authenticating user 'bob'.\n",
      "2025-03-01 16:32:00,400 INFO [Process] - Processing data batch 42.\n",
      "2025-03-01 16:32:30,500 WARNING [Process] - Data batch 42 processing delayed due to network latency.\n",
      "2025-03-01 16:33:00,600 INFO [Process] - Data batch 42 processed successfully.\n",
      "2025-03-01 16:34:00,700 DEBUG [Cleanup] - Cleanup routine started.\n",
      "2025-03-01 16:34:10,800 INFO [Cleanup] - Cleanup completed.\n",
      "\n",
      "data filtered\n"
     ]
    }
   ],
   "source": [
    "#2.File I/O Operations\n",
    "\n",
    "f = open(\"mixed_logs.log\",\"r\")\n",
    "word = \"ERROR\"\n",
    "filtered = \"\"\n",
    "data = True\n",
    "\n",
    "while data:\n",
    "    data = f.readline()\n",
    "    if word not in data:\n",
    "        filtered += data\n",
    "        \n",
    "print(filtered)\n",
    "f1 = open(\"mixed_filtered_logs.log\",\"w\")\n",
    "\n",
    "f1.write(filtered)\n",
    "\n",
    "f1.close()\n",
    "f.close()\n",
    "print(\"data filtered\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "fee38ed8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'timestamp': '2025-03-01 14:05:00,001', 'severity': 'INFO', 'message': \" User login successful for user 'alice'.\"}\n",
      "{'timestamp': '2025-03-01 14:05:05,002', 'severity': 'DEBUG', 'message': \" Retrieved user data for 'alice' from cache.\"}\n",
      "{'timestamp': '2025-03-01 14:05:10,003', 'severity': 'ERROR', 'message': ' Payment processing failed for transaction ID 12345.'}\n",
      "{'timestamp': '2025-03-01 14:05:15,004', 'severity': 'WARNING', 'message': ' Payment retry scheduled for transaction ID 12345.'}\n",
      "{'timestamp': '2025-03-01 14:05:20,005', 'severity': 'INFO', 'message': ' Payment processing succeeded on retry for transaction ID 12345.'}\n"
     ]
    }
   ],
   "source": [
    "#3.String Manipulation\n",
    "\n",
    "f = open(\"applicaiton_logs.txt\",'r')\n",
    "\n",
    "\n",
    "\n",
    "log = []\n",
    "\n",
    "while True:\n",
    "    data = f.readline()\n",
    "    if not data:    \n",
    "        break\n",
    "    data = data.strip()\n",
    "    if not data:      \n",
    "        continue\n",
    "    parts = data.split(\" \",3)\n",
    "    timestamp = parts[0] + ' ' + parts[1]\n",
    "    severity = parts[2]\n",
    "    _ ,message = parts[3].split(\"-\",1)\n",
    "    \n",
    "    log.append({\"timestamp\":timestamp,\"severity\":severity,\"message\":message})\n",
    "\n",
    "f.close()\n",
    "    \n",
    "for logs in log:\n",
    "    print(logs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "0c9b4bcf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['pavanbharadwaj03@gmail.com', 'pavan@gmail.com', 'bharadwaj@gmail.com', 'anu@email.com']\n"
     ]
    }
   ],
   "source": [
    "#4.Regular Expressions (Optional)\n",
    "import re\n",
    "f = open(\"untitled.txt\",\"r\")\n",
    "\n",
    "pattern = '[a-z0-9]+@[a-z]+\\.com'\n",
    "\n",
    "data = f.read()\n",
    "\n",
    "match = re.findall(pattern,data,re.MULTILINE)\n",
    "print(match)\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "969cf97e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The frequency of each word:\n",
      " {'2025-03-01': 5, '14:05:00,001': 1, 'INFO': 2, 'ModuleA': 3, '-': 5, 'User': 1, 'login': 1, 'successful': 1, 'for': 5, 'user': 2, \"'alice'.\": 1, '14:05:05,002': 1, 'DEBUG': 1, 'ModuleB': 1, 'Retrieved': 1, 'data': 1, \"'alice'\": 1, 'from': 1, 'cache.': 1, '14:05:10,003': 1, 'ERROR': 1, 'ModuleC': 1, 'Payment': 3, 'processing': 2, 'failed': 1, 'transaction': 3, 'ID': 3, '12345.': 3, '14:05:15,004': 1, 'WARNING': 1, 'retry': 2, 'scheduled': 1, '14:05:20,005': 1, 'succeeded': 1, 'on': 1}\n"
     ]
    }
   ],
   "source": [
    "#6.Functions and Modular Programming\n",
    "def func():\n",
    "    f = open(\"applicaiton_logs.txt\",\"r\")\n",
    "\n",
    "    data = f.read()\n",
    "\n",
    "    words = data.split()\n",
    "    freq = {}\n",
    "\n",
    "    for word in words:\n",
    "        freq[word] = freq.get(word,0)+1\n",
    "    \n",
    "    f.close()\n",
    "    \n",
    "    print(\"The frequency of each word:\\n\",freq)\n",
    "\n",
    "func()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "285607a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'INFO': 28, 'DEBUG': 19, 'WARNING': 3, 'ERROR': 1}\n"
     ]
    }
   ],
   "source": [
    "#7.Data Structures: Lists, Dictionaries, and Sets  \n",
    "severity_counts = {}\n",
    "\n",
    "with open(\"large_log.txt\", \"r\") as f:\n",
    "    for line in f:\n",
    "        parts = line.split()\n",
    "        if len(parts) > 2:\n",
    "            severity = parts[2].replace(\":\", \"\")\n",
    "            if severity in severity_counts:\n",
    "                severity_counts[severity] += 1\n",
    "            else:\n",
    "                severity_counts[severity] = 1\n",
    "\n",
    "print(severity_counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9a5f4648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['2025-03-01 10:00:00,100 INFO: [Start] - Batch processing started.\\n', '2025-03-01 10:00:05,150 DEBUG: [Process] - Step 1 initiated.\\n', '2025-03-01 10:00:10,200 INFO: [Process] - Step 1 completed.\\n', '2025-03-01 10:00:15,250 DEBUG: [Process] - Step 2 initiated.\\n', '2025-03-01 10:00:20,300 INFO: [Process] - Step 2 completed.\\n', '2025-03-01 10:00:25,350 DEBUG: [Process] - Step 3 initiated.\\n', '2025-03-01 10:00:30,400 INFO: [Process] - Step 3 completed.\\n', '2025-03-01 10:00:35,450 WARNING: [Process] - Slow response detected.\\n', '2025-03-01 10:00:40,500 INFO: [Process] - Retrying step 3.\\n', '2025-03-01 10:00:45,550 INFO: [Process] - Step 3 completed after retry.\\n', '2025-03-01 10:00:50,600 DEBUG: [Monitor] - Checking system status.\\n', '2025-03-01 10:00:55,650 INFO: [Monitor] - System status nominal.\\n', '2025-03-01 10:01:00,700 DEBUG: [Data] - Loading batch 1.\\n', '2025-03-01 10:01:05,750 INFO: [Data] - Batch 1 loaded.\\n', '2025-03-01 10:01:10,800 DEBUG: [Data] - Processing batch 1.\\n', '2025-03-01 10:01:15,850 INFO: [Data] - Batch 1 processed successfully.\\n', '2025-03-01 10:01:20,900 DEBUG: [Data] - Loading batch 2.\\n', '2025-03-01 10:01:25,950 INFO: [Data] - Batch 2 loaded.\\n', '2025-03-01 10:01:30,1000 DEBUG: [Data] - Processing batch 2.\\n', '2025-03-01 10:01:40,1100 INFO: [Data] - Retrying batch 2.\\n', '2025-03-01 10:01:45,1150 DEBUG: [Data] - Processing batch 2 again.\\n', '2025-03-01 10:01:50,1200 INFO: [Data] - Batch 2 processed successfully.\\n', '2025-03-01 10:01:55,1250 INFO: [Summary] - Processing summary: Batch 1 succeeded, Batch 2 retried.\\n', '2025-03-01 10:02:00,1300 DEBUG: [Cleanup] - Initiating cleanup.\\n', '2025-03-01 10:02:05,1350 INFO: [Cleanup] - Temporary files removed.\\n', '2025-03-01 10:02:10,1400 DEBUG: [Cleanup] - Verifying cleanup.\\n', '2025-03-01 10:02:15,1450 INFO: [Cleanup] - Cleanup verified successfully.\\n', '2025-03-01 10:02:20,1500 INFO: [Report] - Generating report.\\n', '2025-03-01 10:02:25,1550 DEBUG: [Report] - Report details: Batch 1 and 2 processing logs.\\n', '2025-03-01 10:02:30,1600 INFO: [Report] - Report generated and saved.\\n', '2025-03-01 10:02:35,1650 INFO: [Finish] - Batch processing completed.\\n', '2025-03-01 10:02:40,1700 DEBUG: [Monitor] - Final system check.\\n', '2025-03-01 10:02:45,1750 INFO: [Monitor] - System operating normally.\\n', '2025-03-01 10:02:50,1800 WARNING: [Monitor] - Potential issue detected: High load.\\n', '2025-03-01 10:02:55,1850 DEBUG: [Monitor] - Investigating high load.\\n', '2025-03-01 10:03:00,1900 INFO: [Monitor] - Load normalized.\\n', '2025-03-01 10:03:05,1950 INFO: [Audit] - Logging end-of-day summary.\\n', '2025-03-01 10:03:10,2000 DEBUG: [Audit] - Summary: All systems nominal.\\n', '2025-03-01 10:03:15,2050 INFO: [Audit] - Audit log updated.\\n', '2025-03-01 10:03:20,2100 DEBUG: [Update] - Checking for software updates.\\n', '2025-03-01 10:03:25,2150 INFO: [Update] - No updates available.\\n', '2025-03-01 10:03:30,2200 DEBUG: [Security] - Scanning for vulnerabilities.\\n', '2025-03-01 10:03:35,2250 INFO: [Security] - Security scan completed.\\n', '2025-03-01 10:03:40,2300 WARNING: [Security] - Unusual activity detected.\\n', '2025-03-01 10:03:45,2350 INFO: [Security] - Notifying admin.\\n', '2025-03-01 10:03:50,2400 DEBUG: [Network] - Monitoring network traffic.\\n', '2025-03-01 10:03:55,2450 INFO: [Network] - Network traffic within normal parameters.\\n', '2025-03-01 10:04:00,2500 DEBUG: [Performance] - Analyzing system performance.\\n', '2025-03-01 10:04:05,2550 INFO: [Performance] - Performance metrics logged.\\n', '2025-03-01 10:04:10,2600 INFO: [System] - System shutdown sequence initiated.\\n']\n"
     ]
    }
   ],
   "source": [
    "#8.List and Dictionary Comprehensions\n",
    "\n",
    "msg = \"ERROR\"\n",
    "with open(\"large_log.txt\",'r') as f:\n",
    "    lsts = [x for x in f if msg not in x]\n",
    "    print(lsts)\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "e6040173",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Status Counts: {'Passed': 5, 'Failed': 3}\n",
      "Average Execution Time: 2.0\n"
     ]
    }
   ],
   "source": [
    "#Task 7\n",
    "\n",
    "import csv\n",
    "\n",
    "file_path = \"test_results.csv\"\n",
    "\n",
    "status_counts = {}\n",
    "execution_times = []\n",
    "\n",
    "with open(file_path, \"r\") as f:\n",
    "    reader = csv.DictReader(f)\n",
    "    for row in reader:\n",
    "        status = row[\"Status\"]\n",
    "        time = float(row[\"ExecutionTime\"])\n",
    "\n",
    "        if status in status_counts:\n",
    "            status_counts[status] += 1\n",
    "        else:\n",
    "            status_counts[status] = 1\n",
    "\n",
    "        execution_times.append(time)\n",
    "\n",
    "average_time = sum(execution_times) / len(execution_times)\n",
    "\n",
    "\n",
    "print(\"Status Counts:\", status_counts)\n",
    "print(\"Average Execution Time:\", round(average_time, 2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "668bbe0d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'config.json'"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Tass 8\n",
    "#JSON Configuration Updater\n",
    "\n",
    "import json\n",
    "\n",
    "config_data = {\n",
    "    \"appName\": \"DataProcessor\",\n",
    "    \"version\": \"1.0.0\",\n",
    "    \"features\": {\n",
    "        \"logging\": True,\n",
    "        \"debugMode\": False,\n",
    "        \"autoUpdate\": True\n",
    "    },\n",
    "    \"maxThreads\": 4\n",
    "}\n",
    "\n",
    "json_file = \"config.json\"\n",
    "with open(json_file, \"w\") as f:\n",
    "    json.dump(config_data, f, indent=4)\n",
    "\n",
    "try:\n",
    "    with open(json_file, \"r\") as f:\n",
    "        config = json.load(f)\n",
    "\n",
    "    config[\"version\"] = \"1.1.0\"              # update version number\n",
    "    config[\"features\"][\"debugMode\"] = True  # toggle debug mode on\n",
    "    config[\"maxThreads\"] = 8                 # increase max threads\n",
    "\n",
    "    # Write back modified config\n",
    "    with open(json_file, \"w\") as f:\n",
    "        json.dump(config, f, indent=4)\n",
    "\n",
    "except Exception as e:\n",
    "    print(\"Error while updating config:\", e)\n",
    "\n",
    "json_file\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "03f2578d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CSV data successfully converted to JSON and saved in 'json_file.json'.\n"
     ]
    }
   ],
   "source": [
    "#task 10\n",
    "\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_json(csv_file_path, json_file_path):\n",
    "    data = []\n",
    "\n",
    "    with open(csv_file_path, mode='r', encoding='utf-8') as csv_file:\n",
    "        csv_reader = csv.DictReader(csv_file)\n",
    "\n",
    "        for row in csv_reader:\n",
    "            data.append(row)\n",
    "\n",
    "    with open(json_file_path, mode='w', encoding='utf-8') as json_file:\n",
    "        json.dump(data, json_file, indent=4, ensure_ascii=False)\n",
    "\n",
    "    print(f\"CSV data successfully converted to JSON and saved in '{json_file_path}'.\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    csv_file = \"test_results.csv\" \n",
    "    json_file = \"json_file.json\" \n",
    "    csv_to_json(csv_file, json_file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce42f41e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#task 11\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
